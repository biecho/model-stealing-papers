{
  "owasp_id": "ML06",
  "owasp_name": "AI Supply Chain Attacks",
  "total": 2,
  "updated": "2026-01-09",
  "papers": [
    {
      "paper_id": "https://openalex.org/W4298186935",
      "title": "IvySyn: Automated Vulnerability Discovery in Deep Learning Frameworks",
      "abstract": "We present IvySyn, the first fully-automated framework for discovering memory error vulnerabilities in Deep Learning (DL) frameworks. IvySyn leverages the statically-typed nature of native APIs in order to automatically perform type-aware mutation-based fuzzing on low-level kernel code. Given a set of offending inputs that trigger memory safety (and runtime) errors in low-level, native DL (C/C++) code, IvySyn automatically synthesizes code snippets in high-level languages (e.g., in Python), which propagate error-triggering input via high(er)-level APIs. Such code snippets essentially act as \"Proof of Vulnerability\", as they demonstrate the existence of bugs in native code that an attacker can target through various high-level APIs. Our evaluation shows that IvySyn significantly outperforms past approaches, both in terms of efficiency and effectiveness, in finding vulnerabilities in popular DL frameworks. Specifically, we used IvySyn to test TensorFlow and PyTorch. Although still an early prototype, IvySyn has already helped the TensorFlow and PyTorch framework developers to identify and fix 61 previously-unknown security vulnerabilities, and assign 39 unique CVEs.",
      "year": 2022,
      "venue": "arXiv (Cornell University)",
      "authors": [
        "Neophytos Christou",
        "Di Jin",
        "Vaggelis Atlidakis",
        "Baishakhi Ray",
        "Vasileios P. Kemerlis"
      ],
      "url": "https://openalex.org/W4298186935",
      "pdf_url": "https://arxiv.org/pdf/2209.14921",
      "cited_by_count": 4,
      "classification_confidence": "HIGH"
    },
    {
      "paper_id": "https://openalex.org/W4399795583",
      "title": "We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs",
      "abstract": "The reliance of popular programming languages such as Python and JavaScript on centralized package repositories and open-source software, combined with the emergence of code-generating Large Language Models (LLMs), has created a new type of threat to the software supply chain: package hallucinations. These hallucinations, which arise from fact-conflicting errors when generating code using LLMs, represent a novel form of package confusion attack that poses a critical threat to the integrity of the software supply chain. This paper conducts a rigorous and comprehensive evaluation of package hallucinations across different programming languages, settings, and parameters, exploring how a diverse set of models and configurations affect the likelihood of generating erroneous package recommendations and identifying the root causes of this phenomenon. Using 16 popular LLMs for code generation and two unique prompt datasets, we generate 576,000 code samples in two programming languages that we analyze for package hallucinations. Our findings reveal that that the average percentage of hallucinated packages is at least 5.2% for commercial models and 21.7% for open-source models, including a staggering 205,474 unique examples of hallucinated package names, further underscoring the severity and pervasiveness of this threat. To overcome this problem, we implement several hallucination mitigation strategies and show that they are able to significantly reduce the number of package hallucinations while maintaining code quality. Our experiments and findings highlight package hallucinations as a persistent and systemic phenomenon while using state-of-the-art LLMs for code generation, and a significant challenge which deserves the research community's urgent attention.",
      "year": 2024,
      "venue": "arXiv (Cornell University)",
      "authors": [
        "Joseph Spracklen",
        "Raveen Wijewickrama",
        "A. H. M. Nazmus Sakib",
        "Anindya Maiti",
        "Murtuza Jadliwala"
      ],
      "url": "https://openalex.org/W4399795583",
      "pdf_url": "https://arxiv.org/pdf/2406.10279",
      "cited_by_count": 2,
      "classification_confidence": "HIGH"
    }
  ]
}