{
  "updated": "2026-01-06",
  "total": 1,
  "owasp_id": "ML02",
  "owasp_name": "Data Poisoning Attack",
  "description": "Attacks that manipulate training data to compromise machine learning models.\n        This includes data poisoning, training data manipulation, backdoor insertion\n        during training, label flipping attacks, and any technique that corrupts\n        the training process by modifying the dataset.",
  "note": "Classified by embeddings (threshold=0.3)",
  "papers": [
    {
      "paper_id": "c74aaca78aa0cfd0eff383f081cdd5440fb03098",
      "title": "Experimental Investigation of Side-Channel Attacks on Neuromorphic Spiking Neural Networks",
      "abstract": "This study investigates the reliability of commonly utilized digital spiking neurons and the potential side-channel vulnerabilities in neuromorphic systems that employ them. Through our experiments, we have successfully decoded the parametric information of Izhikevich and leaky integrate-and-fire (LIF) neuron-based spiking neural networks (SNNs) using differential power analysis. Furthermore, we have demonstrated the practical application of extracted information from the 92% accurate pretrained standard spiking convolution neural network classifier on the FashionMNIST dataset. These findings highlight the potential dangers of utilizing internal information for side-channel and denial-of-service attacks, even when using the usual input as the attack vector.",
      "year": 2024,
      "venue": "IEEE Embedded Systems Letters",
      "authors": [
        "Bhanprakash Goswami",
        "Tamoghno Das",
        "Manan Suri"
      ],
      "citation_count": 2,
      "url": "https://www.semanticscholar.org/paper/c74aaca78aa0cfd0eff383f081cdd5440fb03098",
      "pdf_url": "",
      "publication_date": "2024-06-01",
      "keywords_matched": [
        "side-channel attack (title)"
      ],
      "first_seen": "2025-12-05"
    }
  ]
}